{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Program is evaluate the Testing Accuracy On Our Custome created Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " # For custom datasets and this function is used to lode Testing  dataset\n",
    "\n",
    "from torch.utils.data.dataset import Dataset \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "from random import *\n",
    "from random import randint\n",
    "class CustomDatasetFromImagesForTesting(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform_def: pytorch transforms for transforms and tensor conversion \n",
    "        \"\"\"\n",
    "        self.to_pure_tensor =transforms.Compose([\n",
    "           \n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        # Third column is for an operation indicator\n",
    "        self.operation_arr = np.asarray(self.data_info.iloc[:, 2])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = Image.open(single_image_name,'r')\n",
    "        img_as_img = PIL.ImageOps.invert(img_as_img)\n",
    "        #convart the image into RGB format\n",
    "        img_as_img=img_as_img.convert('RGB')\n",
    "        new_width  = 32\n",
    "        new_height = 32\n",
    "        #resizeing the image into 32x32 \n",
    "        img_as_img = img_as_img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "        #adjust the contrast with factor 1.7\n",
    "        img_as_img=transforms.functional.adjust_contrast(img_as_img,1.7)\n",
    "        # Check if there is an operation\n",
    "        some_operation = self.operation_arr[index]\n",
    "        # If there is an operation\n",
    "        if some_operation:\n",
    "            # Do some operation on image\n",
    "            # ...no operations is happen\n",
    "            # ...\n",
    "            pass\n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = self.to_pure_tensor(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lodeing BDNet own test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting our custome created datasamples for testing \n",
    "from zipfile import ZipFile\n",
    "zf = ZipFile('own.zip', 'r')\n",
    "zf.extractall('./')\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Confution matrics on Custome made Our own DataSamples:-\n",
      "\n",
      "100\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "\n",
      "0\t100\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
      "\n",
      "0\t0\t100\t0\t0\t0\t0\t0\t0\t0\t\n",
      "\n",
      "0\t0\t0\t100\t0\t0\t0\t0\t0\t0\t\n",
      "\n",
      "0\t0\t0\t0\t100\t0\t0\t0\t0\t0\t\n",
      "\n",
      "6\t0\t0\t1\t0\t90\t2\t0\t1\t0\t\n",
      "\n",
      "0\t0\t0\t1\t0\t0\t99\t0\t0\t0\t\n",
      "\n",
      "1\t0\t2\t0\t0\t0\t0\t97\t0\t0\t\n",
      "\n",
      "0\t0\t8\t0\t0\t0\t1\t0\t91\t0\t\n",
      "\n",
      "0\t2\t0\t0\t0\t0\t0\t0\t0\t98\t\n",
      "\n",
      "Final testing accuracy on Our Own Datasamples:  97.5  %\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.onnx as ax\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch,torchvision\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lode the Best model's state , that is parfect fitted model from above traning process \n",
    "the_model = torch.load('./BDNet.pth', map_location='cpu' )   # Since we test on our own pc so, map_location='cpu'\n",
    "#create an array of 10x10 dimension and initialize each field with 0\n",
    "c_mat= [[0 for i in range(10)] for i in range(10)]\n",
    "for kkk in range(10):\n",
    "  for hhh in range(10):\n",
    "    c_mat[kkk][hhh]=0\n",
    "#lode the IsI test datasamples\n",
    "cvs_file_fr_test_beng =CustomDatasetFromImagesForTesting('./own/owndta.csv')\n",
    "\n",
    "tesst_loader = torch.utils.data.DataLoader(dataset=cvs_file_fr_test_beng,batch_size=1, shuffle=True)\n",
    "ttl=0\n",
    "crect=0\n",
    "the_model.eval()\n",
    "for i, (input, target) in enumerate(tesst_loader):\n",
    "  \n",
    "  input_var = torch.autograd.Variable(input, volatile=True)\n",
    "  output = the_model(input_var)\n",
    "  res=output.max(1, keepdim=True)[1]\n",
    "  # fff holdes the predicted output class by our model\n",
    "  # target holdes the actual output class \n",
    "  fff=res.tolist()[0][0]\n",
    "  if(int(target)==int(fff)) :     #if the model predict correctly\n",
    "     crect = crect+1\n",
    "  ttl=ttl+1\n",
    "  c_mat[int(target)][int(fff)]=c_mat[int(target)][int(fff)] + 1\n",
    "  \n",
    "print(\"\\n\\n Confution matrics on Custome made Our own DataSamples:-\\n\")\n",
    "for kkk in range(10):\n",
    "  for hhh in range(10):\n",
    "    print(c_mat[kkk][hhh],end=\"\\t\")\n",
    "  print(\"\\n\")   \n",
    "print(\"Final testing accuracy on Our Own Datasamples: \",(crect/ttl)*100,\" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
